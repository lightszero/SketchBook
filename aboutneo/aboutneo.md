# 关于修改NEO的一些思考

# 一、工程组织方面
## 1.neo项目代码全集中在一起，考虑适当的切分为多个模块
## 2.目前neo是单进程的，部署在一台电脑上，(已经引入了 akka.net ,未来可以分布式)

# 二、P2P网络方面

## 1.网络实现的改进
NEO的网络直接用了C# 的socket实现，这个实现是比较低效的。换用SocketAsyncEventArgs来实现可以提高节点通讯的连接能力，降低网络传输的cpu占用

## 2.网络设置的改进
目前NEO的节点默认listen指定端口，发起连接的目标地址均为对方的出站IP和默认端口，实际上不太符合网络配置的习惯。

a.每个节点可以绑定一个 listen的 ipendpoint
b.每个节点可以指定多个通知别人如何连接自己的 ipendpoint

这样在部署节点时，可以直接在网关设备做端口转发
连接到多个网关设备的节点也很容易配置

# 三.共识方面
## 1.考虑DBFT+VRF
## 2.考虑让共识节点之间维护一个完全一致的未交易列表

先让共识节点之间维护一个完全一致的未交易列表，让共识时不要发生缺交易的情况

## 3.考虑限制鉴权合约的能力
因为鉴权智能合约的存在，可以访问任何状态，作为校验的条件，这导致了每一个出块操作都可能依赖之前的状态，也就限制了，出块和同步工作不能分开。

如果鉴权合约仅仅只能做签名检查和当前块、时间戳这类不依赖状态的属性（尤其是不依赖Stroage），就可以共识节点完全不需要跑同步逻辑，将极大提升共识性能

将复杂的逻辑迁移到应用合约中去


# 四、同步方面
## 1.notify 不应该是一个插件
一个智能合约的输出，一共就两种方式，写Storage,notify
这是一个非常重要的部分，不应该是一个可选组件。
## 2.让交易可以并行同步
区块链逻辑是串行化的，我不打算改变这一点，但是可以改变一些细节

块-》块之间逻辑是串行化的，这一点坚持

但是同一个块之内的交易，可不可以做到互不干涉呢？
主要的问题在于以下两个

    a.多个交易同时写入同一个Storage 的同一个Key
    b.一个交易要读一个Storage 的key，而同一个块中有另一笔交易要写入他

a 和 b 都会产生顺序性要求

对b问题比较好解，令所有交易初始的Storage的值都是上一个块的状态，这样就消除了问题b的顺序要求，这会带来一个小小的变化，同一个块中刚写的storage，在当前块中无法被别的交易感知。我认为这个变化没有什么破坏性

对a问题是无法解的，如果导入对于有同一个key的交易依然保持顺序性的设计，这个并行就很不彻底。所以我的设计是对a问题，同一个块中不允许写入同一个key，如果有这样的交易，只收录一笔，其它的后面的块再收录。

但是这就产生了另一个问题，如果共识节点只跑鉴证逻辑，他们怎么知道谁要写入哪个key？，怎么才能提前筛出他来，所以还需要一个附加的设计，每笔交易都有一个字段先标明他要写入的Storage.Key,不标不让写入。对于其它的状态改变也是如此。

ok，这样还不够，这样会过滤掉太多的交易，导致很多交易变成一块最多一笔。所以可以增加个加法器设计。比如所有人都给X转账，X的余额的变化就是+2 +3 +4,全是加法，根据加法交换律，且没有if截断数据，加法交易可以随意顺序处置。所以使用加法器的交易可以并发。

并且加法器还可以减少数据库写入次数，所有成功交易的加法器，累计到block同步完毕，内次里加好在写入。

你肯定在想减法器，这是不行的，因为大部分的减法交易都有if(xx<0)的判断存在，导致这样的交易不满足交换律。

# 五、存储方面
## 1.rocksdb
facebook对rocksdb的优化，让即使什么也不做，rocksdb 就比leveldb快一点
（初步对比测试结论，快20%，测试方法，1K小数据写100M）
## 2.独立数据库模块
IO的瓶颈会被一台计算机的硬盘写入性能绑死。

但是keyvalue数据库的一大优势就是容易分布到集群中去分布存储

要利用这个优势，首先数据库模块就得是个独立的进程，通过网络和主模块通讯

# 六、智能合约方面
## 1.分函数，多入口
现在唯一Main入口的方式，其实Main里面的代码就蛮浪费的，分开多个入口，会更清晰
## 2.增加一些事件性质的设计

比如智能合约发布时，执行哪个函数，之类的

## 3.更精细的整数类型
bigintger 虽然万用，但是性能远低于 uint64 uint32这些，可以考虑加入